{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(132)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Non-Linear Regression Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def synthetic_data1d(n, alpha):\n",
    "    x = np.random.uniform(-(3/2)*np.pi, np.pi/2, size=n)\n",
    "    y = np.cos(x) * np.exp(np.sin(x) + alpha*np.random.normal(size=n))\n",
    "    return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def synthetic_data2d(n, alpha):\n",
    "    noise_x = alpha*np.random.normal(size=n)\n",
    "    noise_y = alpha*np.random.normal(size=n)\n",
    "    x = np.random.uniform(-2*np.pi, 2*np.pi, size=(n, 2))\n",
    "    y = np.sin(np.cos(x[:, 1]) + noise_x) + np.exp(np.cos(x[:, 0]) + noise_y)\n",
    "    return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "n1 = 100\n",
    "n2 = 1000\n",
    "alpha = 0.05"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 1d example\n",
    "N = 1000\n",
    "true_x = np.linspace(-(3 / 2) * np.pi, np.pi / 2, N)\n",
    "true_y = np.cos(true_x) * np.exp(np.sin(true_x))\n",
    "x, y = synthetic_data1d(n1, alpha)\n",
    "plt.figure(1)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(true_x, true_y, color='red')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 2d example\n",
    "N = 50\n",
    "xx = np.linspace(-2*np.pi, 2*np.pi, N)\n",
    "xv, yv = np.meshgrid(xx, xx)\n",
    "z = np.empty(N*N)\n",
    "c = 0\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        z[c] = np.sin(np.cos(yv[i, j])) + np.exp(np.cos(xv[i, j]))\n",
    "        c += 1\n",
    "\n",
    "fig = plt.figure(2)\n",
    "ax = plt.axes(projection='3d')\n",
    "X, Y = synthetic_data2d(n2, alpha)\n",
    "\n",
    "ax.scatter(xv.flatten(), yv.flatten(), z, color='black', alpha=0.2)\n",
    "# ax.scatter(X[:,0], X[:,1], Y, color='red')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 08:21:10.564944: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Rescale data between 0 and 1\n",
    "data_max = np.max(X)\n",
    "data_min = np.min(X)\n",
    "X = (X - data_min) / (data_max - data_min)\n",
    "# Split up data\n",
    "train_split = 0.8\n",
    "batch_size = 64\n",
    "num_data = len(Y)\n",
    "train_x = X[0:int(num_data*train_split), :]\n",
    "train_y = Y[0:int(num_data*train_split)]\n",
    "test_x = X[int(num_data*train_split):, :]\n",
    "test_y = Y[int(num_data*train_split):]\n",
    "# convert to tensors\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "# shuffle and batch\n",
    "train_dataset = train_dataset.shuffle(int(num_data*train_split)).batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Serial Neural Network Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu', input_shape=(2,)))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "  if epoch < 45:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.05)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.3434 - lr: 0.0100\n",
      "Epoch 2/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.0149 - lr: 0.0100\n",
      "Epoch 3/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9857 - lr: 0.0100\n",
      "Epoch 4/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9893 - lr: 0.0100\n",
      "Epoch 5/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9420 - lr: 0.0100\n",
      "Epoch 6/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8827 - lr: 0.0100\n",
      "Epoch 7/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8435 - lr: 0.0100\n",
      "Epoch 8/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8091 - lr: 0.0100\n",
      "Epoch 9/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8137 - lr: 0.0100\n",
      "Epoch 10/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7749 - lr: 0.0100\n",
      "Epoch 11/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7657 - lr: 0.0100\n",
      "Epoch 12/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7863 - lr: 0.0100\n",
      "Epoch 13/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7687 - lr: 0.0100\n",
      "Epoch 14/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7840 - lr: 0.0100\n",
      "Epoch 15/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7531 - lr: 0.0100\n",
      "Epoch 16/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7434 - lr: 0.0100\n",
      "Epoch 17/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7974 - lr: 0.0100\n",
      "Epoch 18/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7961 - lr: 0.0100\n",
      "Epoch 19/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7297 - lr: 0.0100\n",
      "Epoch 20/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7268 - lr: 0.0100\n",
      "Epoch 21/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7019 - lr: 0.0100\n",
      "Epoch 22/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6859 - lr: 0.0100\n",
      "Epoch 23/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6817 - lr: 0.0100\n",
      "Epoch 24/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6408 - lr: 0.0100\n",
      "Epoch 25/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5972 - lr: 0.0100\n",
      "Epoch 26/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5705 - lr: 0.0100\n",
      "Epoch 27/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5674 - lr: 0.0100\n",
      "Epoch 28/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5642 - lr: 0.0100\n",
      "Epoch 29/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5029 - lr: 0.0100\n",
      "Epoch 30/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4843 - lr: 0.0100\n",
      "Epoch 31/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4829 - lr: 0.0100\n",
      "Epoch 32/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4653 - lr: 0.0100\n",
      "Epoch 33/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3977 - lr: 0.0100\n",
      "Epoch 34/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3381 - lr: 0.0100\n",
      "Epoch 35/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3271 - lr: 0.0100\n",
      "Epoch 36/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3383 - lr: 0.0100\n",
      "Epoch 37/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2694 - lr: 0.0100\n",
      "Epoch 38/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2285 - lr: 0.0100\n",
      "Epoch 39/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2059 - lr: 0.0100\n",
      "Epoch 40/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1710 - lr: 0.0100\n",
      "Epoch 41/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1416 - lr: 0.0100\n",
      "Epoch 42/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1310 - lr: 0.0100\n",
      "Epoch 43/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1038 - lr: 0.0100\n",
      "Epoch 44/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1051 - lr: 0.0100\n",
      "Epoch 45/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0851 - lr: 0.0100\n",
      "Epoch 46/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0768 - lr: 0.0095\n",
      "Epoch 47/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0682 - lr: 0.0090\n",
      "Epoch 48/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0523 - lr: 0.0086\n",
      "Epoch 49/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0485 - lr: 0.0082\n",
      "Epoch 50/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0465 - lr: 0.0078\n",
      "Epoch 51/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0392 - lr: 0.0074\n",
      "Epoch 52/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0441 - lr: 0.0070\n",
      "Epoch 53/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0350 - lr: 0.0067\n",
      "Epoch 54/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0349 - lr: 0.0064\n",
      "Epoch 55/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0372 - lr: 0.0061\n",
      "Epoch 56/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0337 - lr: 0.0058\n",
      "Epoch 57/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0320 - lr: 0.0055\n",
      "Epoch 58/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0322 - lr: 0.0052\n",
      "Epoch 59/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0270 - lr: 0.0050\n",
      "Epoch 60/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0262 - lr: 0.0047\n",
      "Epoch 61/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0293 - lr: 0.0045\n",
      "Epoch 62/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0270 - lr: 0.0043\n",
      "Epoch 63/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0288 - lr: 0.0041\n",
      "Epoch 64/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0262 - lr: 0.0039\n",
      "Epoch 65/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0232 - lr: 0.0037\n",
      "Epoch 66/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0235 - lr: 0.0035\n",
      "Epoch 67/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0215 - lr: 0.0033\n",
      "Epoch 68/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0226 - lr: 0.0032\n",
      "Epoch 69/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0215 - lr: 0.0030\n",
      "Epoch 70/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0207 - lr: 0.0029\n",
      "Epoch 71/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0216 - lr: 0.0027\n",
      "Epoch 72/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0204 - lr: 0.0026\n",
      "Epoch 73/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0188 - lr: 0.0025\n",
      "Epoch 74/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0190 - lr: 0.0023\n",
      "Epoch 75/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0190 - lr: 0.0022\n",
      "Epoch 76/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0189 - lr: 0.0021\n",
      "Epoch 77/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0184 - lr: 0.0020\n",
      "Epoch 78/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0181 - lr: 0.0019\n",
      "Epoch 79/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0186 - lr: 0.0018\n",
      "Epoch 80/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0185 - lr: 0.0017\n",
      "Epoch 81/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0177 - lr: 0.0017\n",
      "Epoch 82/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0176 - lr: 0.0016\n",
      "Epoch 83/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0184 - lr: 0.0015\n",
      "Epoch 84/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0180 - lr: 0.0014\n",
      "Epoch 85/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0175 - lr: 0.0014\n",
      "Epoch 86/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0168 - lr: 0.0013\n",
      "Epoch 87/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0166 - lr: 0.0012\n",
      "Epoch 88/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0171 - lr: 0.0012\n",
      "Epoch 89/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0175 - lr: 0.0011\n",
      "Epoch 90/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0172 - lr: 0.0011\n",
      "Epoch 91/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0170 - lr: 0.0010\n",
      "Epoch 92/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0169 - lr: 9.5369e-04\n",
      "Epoch 93/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0168 - lr: 9.0718e-04\n",
      "Epoch 94/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0166 - lr: 8.6294e-04\n",
      "Epoch 95/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0162 - lr: 8.2085e-04\n",
      "Epoch 96/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0160 - lr: 7.8082e-04\n",
      "Epoch 97/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0160 - lr: 7.4274e-04\n",
      "Epoch 98/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0162 - lr: 7.0651e-04\n",
      "Epoch 99/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0161 - lr: 6.7206e-04\n",
      "Epoch 100/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0158 - lr: 6.3928e-04\n",
      "Epoch 101/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0157 - lr: 6.0810e-04\n",
      "Epoch 102/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0159 - lr: 5.7844e-04\n",
      "Epoch 103/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0156 - lr: 5.5023e-04\n",
      "Epoch 104/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0157 - lr: 5.2340e-04\n",
      "Epoch 105/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0156 - lr: 4.9787e-04\n",
      "Epoch 106/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0157 - lr: 4.7359e-04\n",
      "Epoch 107/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0157 - lr: 4.5049e-04\n",
      "Epoch 108/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0155 - lr: 4.2852e-04\n",
      "Epoch 109/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0154 - lr: 4.0762e-04\n",
      "Epoch 110/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0152 - lr: 3.8774e-04\n",
      "Epoch 111/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0154 - lr: 3.6883e-04\n",
      "Epoch 112/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0154 - lr: 3.5084e-04\n",
      "Epoch 113/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0152 - lr: 3.3373e-04\n",
      "Epoch 114/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0153 - lr: 3.1746e-04\n",
      "Epoch 115/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0155 - lr: 3.0197e-04\n",
      "Epoch 116/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0152 - lr: 2.8725e-04\n",
      "Epoch 117/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0152 - lr: 2.7324e-04\n",
      "Epoch 118/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0151 - lr: 2.5991e-04\n",
      "Epoch 119/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0151 - lr: 2.4724e-04\n",
      "Epoch 120/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0151 - lr: 2.3518e-04\n",
      "Epoch 121/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0151 - lr: 2.2371e-04\n",
      "Epoch 122/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0150 - lr: 2.1280e-04\n",
      "Epoch 123/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0150 - lr: 2.0242e-04\n",
      "Epoch 124/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0150 - lr: 1.9255e-04\n",
      "Epoch 125/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0152 - lr: 1.8316e-04\n",
      "Epoch 126/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0152 - lr: 1.7422e-04\n",
      "Epoch 127/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0150 - lr: 1.6573e-04\n",
      "Epoch 128/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0149 - lr: 1.5764e-04\n",
      "Epoch 129/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0150 - lr: 1.4996e-04\n",
      "Epoch 130/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0149 - lr: 1.4264e-04\n",
      "Epoch 131/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0149 - lr: 1.3569e-04\n",
      "Epoch 132/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0149 - lr: 1.2907e-04\n",
      "Epoch 133/150\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0149 - lr: 1.2277e-04\n",
      "Epoch 134/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0149 - lr: 1.1679e-04\n",
      "Epoch 135/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0149 - lr: 1.1109e-04\n",
      "Epoch 136/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0148 - lr: 1.0567e-04\n",
      "Epoch 137/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0149 - lr: 1.0052e-04\n",
      "Epoch 138/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0148 - lr: 9.5616e-05\n",
      "Epoch 139/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0148 - lr: 9.0953e-05\n",
      "Epoch 140/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0148 - lr: 8.6517e-05\n",
      "Epoch 141/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0148 - lr: 8.2298e-05\n",
      "Epoch 142/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0148 - lr: 7.8284e-05\n",
      "Epoch 143/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0148 - lr: 7.4466e-05\n",
      "Epoch 144/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0148 - lr: 7.0834e-05\n",
      "Epoch 145/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0147 - lr: 6.7380e-05\n",
      "Epoch 146/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0147 - lr: 6.4094e-05\n",
      "Epoch 147/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0147 - lr: 6.0968e-05\n",
      "Epoch 148/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0147 - lr: 5.7994e-05\n",
      "Epoch 149/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0147 - lr: 5.5166e-05\n",
      "Epoch 150/150\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0147 - lr: 5.2475e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x150aded70>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "opt = tf.keras.optimizers.Adam(learning_rate)\n",
    "lossF = tf.keras.losses.MeanSquaredError()\n",
    "model.compile(loss=lossF, optimizer=opt)\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "model.fit(train_dataset, epochs=150, callbacks=[callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0276\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.027639135718345642"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 761us/step\n"
     ]
    }
   ],
   "source": [
    "# test_predictions = model.predict(test_dataset).flatten()\n",
    "X2 = np.vstack((xv.flatten(), yv.flatten())).transpose()\n",
    "X2 = (X2 - np.min(X2)) / (np.max(X2) - np.min(X2))\n",
    "test_predictions = model.predict(X2).flatten()\n",
    "plt.figure(3)\n",
    "plt.scatter(z, test_predictions, color='blue')\n",
    "a = min(np.min(z), np.min(test_predictions)) - 0.5\n",
    "b = max(np.max(z), np.max(test_predictions)) + 0.5\n",
    "e = np.linspace(a,b,100)\n",
    "plt.xlim(a, b)\n",
    "plt.ylim(a,b)\n",
    "plt.plot(e,e, color='black')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "fig = plt.figure(4)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(X2[:,0], X2[:,1], z, color='black', alpha=0.1)\n",
    "ax.scatter(X2[:,0], X2[:,1], test_predictions, color='red')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}