{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Federated Coordination Set Method: Non-Linear Regression Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "n = 4\n",
    "rc = ipp.Cluster(engines=\"mpi\", n=n).start_and_connect_sync()\n",
    "view = rc[:]\n",
    "rc.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%px --block\n",
    "# MPI initialization, library imports and sanity checks on all engines\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from comm_weights import unflatten_weights, flatten_weights\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "%matplotlib qt\n",
    "np.random.seed(132)\n",
    "\n",
    "mpi = MPI.COMM_WORLD\n",
    "bcast = mpi.bcast\n",
    "barrier = mpi.barrier\n",
    "rank = mpi.rank\n",
    "size = mpi.size\n",
    "print(\"MPI rank: %i/%i\" % (mpi.rank,mpi.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " %%px --block\n",
    "def synthetic_data2d(n, alpha):\n",
    "    noise_x = alpha*np.random.normal(size=n)\n",
    "    noise_y = alpha*np.random.normal(size=n)\n",
    "    x = np.random.uniform(-2*np.pi, 2*np.pi, size=(n, 2))\n",
    "    y = np.sin(np.cos(x[:, 1]) + noise_x) + np.exp(np.cos(x[:, 0]) + noise_y)\n",
    "    return x.astype(np.float32), y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " %%px --block \n",
    "# Implement Custom Loss Function\n",
    "@tf.function\n",
    "def consensus_loss(y_true, y_pred, z, l2):\n",
    "\n",
    "    # local error\n",
    "    local_error = y_true - y_pred\n",
    "    local_square_error = tf.square(local_error)\n",
    "    local_mse = tf.reduce_mean(local_square_error)\n",
    "\n",
    "    # consensus loss error\n",
    "    consensus_error = z - y_pred\n",
    "    consensus_square_error = tf.square(consensus_error)\n",
    "    consensus_mse = l2*tf.reduce_sum(consensus_square_error)\n",
    "\n",
    "    return local_mse + consensus_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%px --block\n",
    "def get_model_architecture(model):\n",
    "    # find shape and total elements for each layer of the resnet model\n",
    "    model_weights = model.get_weights()\n",
    "    layer_shapes = []\n",
    "    layer_sizes = []\n",
    "    for i in range(len(model_weights)):\n",
    "        layer_shapes.append(model_weights[i].shape)\n",
    "        layer_sizes.append(model_weights[i].size)\n",
    "    return layer_shapes, layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " %%px --block\n",
    "def model_sync(model, layer_shapes, layer_sizes, size):\n",
    "    # necessary preprocess\n",
    "    model_weights = model.get_weights()\n",
    "    # flatten tensor weights\n",
    "    send_buffer = flatten_weights(model_weights)\n",
    "    recv_buffer = np.zeros_like(send_buffer)\n",
    "    # perform all-reduce to synchronize initial models across all clients\n",
    "    MPI.COMM_WORLD.Allreduce(send_buffer, recv_buffer, op=MPI.SUM)\n",
    "    # divide by total workers to get average model\n",
    "    recv_buffer = recv_buffer / size\n",
    "    # update local models\n",
    "    new_weights = unflatten_weights(recv_buffer, layer_shapes, layer_sizes)\n",
    "    model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%px --block\n",
    "def average_models(model, local_update, layer_shapes, layer_sizes):\n",
    "    model_weights = model.get_weights()\n",
    "    # flatten tensor weights\n",
    "    coordinate_weights = flatten_weights(model_weights)\n",
    "    local_weights = flatten_weights(local_update)\n",
    "    next_weights = unflatten_weights(np.average([coordinate_weights, local_weights], axis=0),\n",
    "                                           layer_shapes, layer_sizes)\n",
    "    # update model weights to average\n",
    "    model.set_weights(next_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " %%px --block\n",
    "# Play around with this more\n",
    "def set_learning_rate(optimizer, epoch):\n",
    "    optimizer.lr = optimizer.lr\n",
    "    #if epoch >= 175:\n",
    "    #    optimizer.lr = 0.005\n",
    "    #elif epoch >= 350:\n",
    "    #    optimizer.lr = 0.001\n",
    "    '''\n",
    "    if epoch <= 30:\n",
    "        optimizer.lr = 0.0025\n",
    "    if 30 < epoch <= 100:\n",
    "        optimizer.lr = 0.0015\n",
    "    elif 100 < epoch <= 200:\n",
    "        optimizer.lr = 0.001\n",
    "    elif 200 < epoch <= 300:\n",
    "        optimizer.lr = 0.0005\n",
    "    elif 300 < epoch <= 400:\n",
    "        optimizer.lr = 0.00045\n",
    "    elif 400 < epoch <= 450:\n",
    "        optimizer.lr = 0.00005\n",
    "    else:\n",
    "        optimizer.lr = 0.00001\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%px --block\n",
    "# 2d mesh example\n",
    "def mesh_grid(N):\n",
    "    xx = np.linspace(-2 * np.pi, 2 * np.pi, N)\n",
    "    xv, yv = np.meshgrid(xx, xx)\n",
    "    z = np.empty(N * N)\n",
    "    c = 0\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            z[c] = np.sin(np.cos(yv[i, j])) + np.exp(np.cos(xv[i, j]))\n",
    "            c += 1\n",
    "    X = np.vstack((xv.flatten(), yv.flatten())).transpose()\n",
    "    X = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
    "    return z, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%px --block\n",
    "# Model evaluation and plots\n",
    "def model_results(model, test_dataset):\n",
    "\n",
    "    # Compile and test model\n",
    "    model.compile(loss=lossF, optimizer=optimizer)\n",
    "    model.evaluate(test_dataset)\n",
    "\n",
    "    # generate test mesh\n",
    "    N = 50\n",
    "    z, X = mesh_grid(N)\n",
    "    \n",
    "    # get predictions from current model\n",
    "    test_predictions = model.predict(X).flatten()\n",
    "    \n",
    "    # plot results\n",
    "    plt.figure(1)\n",
    "    plt.scatter(z, test_predictions, color='blue')\n",
    "    a = min(np.min(z), np.min(test_predictions)) - 0.5\n",
    "    b = max(np.max(z), np.max(test_predictions)) + 0.5\n",
    "    e = np.linspace(a, b, 100)\n",
    "    plt.xlim(a, b)\n",
    "    plt.ylim(a, b)\n",
    "    plt.plot(e, e, color='black')\n",
    "    plt.title('Actual vs. Predicted Values')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(2)\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.scatter(X[:, 0], X[:, 1], z, color='black', alpha=0.1, label='Actual Fit')\n",
    "    ax.scatter(X[:, 0], X[:, 1], test_predictions, color='red', label='Predicted Fit')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.title('Predicted vs. Actual Fit')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%px --block\n",
    "def train(model, lossF, optimizer, train_dataset, coordination_dataset, epochs, coord_batch_size, batches,\n",
    "          layer_shapes, layer_sizes, l2):\n",
    "    loss_metric = tf.keras.metrics.MeanSquaredError()\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Adjust learning rate\n",
    "        set_learning_rate(optimizer, epoch)\n",
    "\n",
    "        # Forward Pass of Coordination Set (get z)\n",
    "        send_predicted = np.zeros((coord_batch_size, batches), dtype=np.float32)\n",
    "        recv_avg_pred = np.zeros((coord_batch_size, batches), dtype=np.float32)\n",
    "        # loss = np.zeros(batches, dtype=np.float64)\n",
    "        for c_batch_idx, (c_data, c_target) in enumerate(coordination_dataset):\n",
    "            pred = model(c_data, training=True)\n",
    "            send_predicted[:, c_batch_idx] = pred.numpy().flatten()\n",
    "\n",
    "        # Communication Process Here\n",
    "        MPI.COMM_WORLD.Allreduce(send_predicted, recv_avg_pred, op=MPI.SUM)\n",
    "        recv_avg_pred = recv_avg_pred / size\n",
    "\n",
    "        # save initial model\n",
    "        start_model = copy.deepcopy(model.get_weights())\n",
    "\n",
    "        # Local Training\n",
    "        for batch_idx, (data, target) in enumerate(train_dataset):\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_p = model(data, training=True)\n",
    "                loss_val = lossF(y_true=target, y_pred=y_p)\n",
    "            grads = tape.gradient(loss_val, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            loss_metric.update_state(target, y_p)\n",
    "\n",
    "        # save model after local update\n",
    "        local_model = copy.deepcopy(model.get_weights())\n",
    "\n",
    "        # reset model weights\n",
    "        model.set_weights(start_model)\n",
    "        # Consensus Training\n",
    "        for c_batch_idx, (c_data, c_target) in enumerate(coordination_dataset):\n",
    "            with tf.GradientTape() as tape:\n",
    "                c_yp = model(c_data, training=True)\n",
    "                loss_val = consensus_loss(y_true=c_target, y_pred=c_yp,\n",
    "                                           z=recv_avg_pred[:, c_batch_idx].reshape(coord_batch_size, 1),\n",
    "                                           l2=l2)\n",
    "\n",
    "            grads = tape.gradient(loss_val, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        # update model weights\n",
    "        average_models(model, local_model, layer_shapes, layer_sizes)\n",
    "\n",
    "        if rank == 0 and epoch % 10 == 0:\n",
    "            print('(Rank %d) Training Loss for Epoch %d: %0.4f' % (rank, epoch, loss_metric.result()))\n",
    "        loss_metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " %%px --block\n",
    "# Hyper-parameters\n",
    "n = 1000\n",
    "alpha = 0.05\n",
    "epochs = 500\n",
    "learning_rate = 0.01\n",
    "l2 = 0.1\n",
    "\n",
    "# 2d example\n",
    "# X, Y = synthetic_data2d(int(n/size), alpha)\n",
    "X, Y = synthetic_data2d(n, alpha)\n",
    "\n",
    "# Rescale data between 0 and 1\n",
    "data_max = np.max(X)\n",
    "data_min = np.min(X)\n",
    "X = (X - data_min) / (data_max - data_min)\n",
    "# Split up data\n",
    "train_split = 0.8\n",
    "batch_size = 64\n",
    "num_data = len(Y)\n",
    "train_x = X[0:int(num_data * train_split), :]\n",
    "train_y = Y[0:int(num_data * train_split)]\n",
    "test_x = X[int(num_data * train_split):, :]\n",
    "test_y = Y[int(num_data * train_split):]\n",
    "# convert to tensors\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "# shuffle and batch\n",
    "train_dataset = train_dataset.shuffle(int(num_data * train_split)).batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "# Coordination set construction\n",
    "coord_size = 160\n",
    "# c_batch_size = 16\n",
    "c_batch_size = 160\n",
    "c_num_batches = int(coord_size/c_batch_size)\n",
    "\n",
    "true_x = np.tile(np.linspace(-2*np.pi, 2*np.pi, coord_size), (2, 1)).transpose()\n",
    "true_y = np.sin(np.cos(true_x[:, 1])) + np.exp(np.cos(true_x[:, 0]))\n",
    "true_x = true_x.astype(np.float32)\n",
    "true_y = true_y.astype(np.float32)\n",
    "coord_max = np.max(true_x)\n",
    "coord_min = np.min(true_x)\n",
    "true_x = (true_x - coord_min) / (coord_max - coord_min)\n",
    "coordination_dataset = tf.data.Dataset.from_tensor_slices((true_x, true_y))\n",
    "coordination_dataset = coordination_dataset.batch(c_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%px --block\n",
    "# Initialize Model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu', input_shape=(2,)))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# get model architecture\n",
    "layer_shapes, layer_sizes = get_model_architecture(model)\n",
    "\n",
    "# Initialize Local Loss Function\n",
    "lossF = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# Initialize Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%px --block\n",
    "# Sync model weights\n",
    "model_sync(model, layer_shapes, layer_sizes, size)\n",
    "MPI.COMM_WORLD.Barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%px --block\n",
    "train(model, lossF, optimizer, train_dataset, coordination_dataset, epochs, c_batch_size, c_num_batches, \n",
    "     layer_shapes, layer_sizes, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f0233e18a142ba8749cc04a26171cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "%px:   0%|          | 0/4 [00:00<?, ?tasks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --block\n",
    "if mpi.rank == 0:\n",
    "    model_results(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
